ä½œä¸ºä¸€åå¼€å‘è€…ï¼Œåœ¨å¤§æ¨¡å‹è¿™ä¹ˆçƒ­çš„ä»Šå¤©ï¼Œå†³å®šä¸èƒ½è½ä¸‹ï¼Œå¼€å§‹å­¦èµ·æ¥ï¼Œæœ‰å…´è¶£çš„æœ‹å‹å¯ä»¥ä¸€èµ·ï¼Œä»Šå¤©åœ¨[langchainå®˜ç½‘](https://docs.langchain.com/oss/python/langgraph/overview)ï¼Œå¤§è‡´çœ‹äº†ä¸‹ï¼Œå†³å®šå…ˆæ¥ä¸ªä¾‹å­æ„Ÿå—ä¸€ä¸‹ï¼Œç„¶ååœ¨å­¦ä¹ æ¦‚å¿µï¼Œå‡†å¤‡ç›´æ¥æ‹¿å®˜æ–¹çš„è®¡ç®—å™¨Agentæ¥ç»ƒæ‰‹ï¼å®˜æ–¹ä¾‹å­ä»£ç å¦‚ä¸‹ï¼š<https://docs.langchain.com/oss/python/langgraph/quickstart>ã€‚æˆ‘æŠŠå¤§æ¨¡å‹æ›¿æ¢æˆäº†åƒé—®ï¼Œå…¶ä»–éƒ½æ²¡å˜ã€‚

## ç¯å¢ƒå‡†å¤‡

> pythonï¼š3.12 ç¼–è¯‘å™¨ï¼šPyCharm pythonä¾èµ–åŒ…ï¼šlangchainã€langgraphã€langchain\_communityã€dashscopeã€dotenv

pythonä¾èµ–åŒ…é€šè¿‡PyCharm->Preferences->Project->Python Interpreteræ·»åŠ 

## å®Œæ•´ä»£ç 

    # Step 1: å®šä¹‰å·¥å…·å’Œæ¨¡å‹
    import os
    from langchain.tools import tool
    from langchain_community.chat_models import ChatTongyi
    from dotenv import load_dotenv

    load_dotenv()

    # åˆå§‹åŒ– Qwen æ¨¡å‹ï¼ˆé€šè¿‡ DashScope çš„ OpenAI å…¼å®¹æ¥å£ï¼‰
    model = ChatTongyi(
        model="qwen-max",
        temperature=0,
        dashscope_api_key=os.getenv("DASHSCOPE_API_KEY")
    )


    # å®šä¹‰å·¥å…·
    @tool
    def multiply(a: int, b: int) -> int:
        """Multiply `a` and `b`.

        Args:
            a: First int
            b: Second int
        """
        return a * b


    @tool
    def add(a: int, b: int) -> int:
        """Adds `a` and `b`.

        Args:
            a: First int
            b: Second int
        """
        return a + b


    @tool
    def divide(a: int, b: int) -> float:
        """Divide `a` and `b`.

        Args:
            a: First int
            b: Second int
        """
        return a / b


    # æ¨¡å‹ç»‘å®šå·¥å…·
    tools = [add, multiply, divide]
    tools_by_name = {tool.name: tool for tool in tools}
    model_with_tools = model.bind_tools(tools)

    # Step 2: å®šä¹‰çŠ¶æ€

    from langchain.messages import AnyMessage
    from typing_extensions import TypedDict, Annotated
    import operator


    class MessagesState(TypedDict):
        messages: Annotated[list[AnyMessage], operator.add]
        llm_calls: int

    # Step 3: å®šä¹‰æ¨¡å‹Node
    from langchain.messages import SystemMessage
    import json

    def llm_call(state: dict):
        """LLM decides whether to call a tool or not"""

        return {
            "messages": [
                model_with_tools.invoke(
                    [
                        SystemMessage(
                            content="You are a helpful assistant tasked with performing arithmetic on a set of inputs."
                        )
                    ]
                    + state["messages"]
                )
            ],
            "llm_calls": state.get('llm_calls', 0) + 1
        }


    # Step 4: å®šä¹‰å·¥å…·Node

    from langchain.messages import ToolMessage

    def tool_node(state: dict):
        """Performs the tool call"""

        result = []
        for tool_call in state["messages"][-1].tool_calls:
            tool = tools_by_name[tool_call["name"]]
            observation = tool.invoke(tool_call["args"])
            result.append(ToolMessage(content=observation, tool_call_id=tool_call["id"]))
        return {"messages": result}

    # Step 5: å®šä¹‰é€»è¾‘å†³å®šæ˜¯å¦ç»“æŸï¼Œè¿˜æ˜¯æ‰§è¡Œå·¥å…·è°ƒç”¨

    from typing import Literal
    from langgraph.graph import StateGraph, START, END


    # Conditional edge function to route to the tool node or end based upon whether the LLM made a tool call
    def should_continue(state: MessagesState) -> Literal["tool_node", END]:
        """Decide if we should continue the loop or stop based upon whether the LLM made a tool call"""

        messages = state["messages"]
        last_message = messages[-1]

        # If the LLM makes a tool call, then perform an action
        if last_message.tool_calls:
            return "tool_node"

        # Otherwise, we stop (reply to the user)
        return END

    # Step 6: Build agent

    # Build workflow
    agent_builder = StateGraph(MessagesState)

    # æ·»åŠ Node
    agent_builder.add_node("llm_call", llm_call)
    agent_builder.add_node("tool_node", tool_node)

    # Add edges to connect nodes
    agent_builder.add_edge(START, "llm_call")
    agent_builder.add_conditional_edges(
        "llm_call",
        should_continue,
        ["tool_node", END]
    )
    agent_builder.add_edge("tool_node", "llm_call")

    # ç¼–è¯‘ the agent
    agent = agent_builder.compile()

    # Show the agent
    # print(agent.get_graph(xray=True).draw_mermaid())

    # Invoke
    from langchain.messages import HumanMessage
    from langchain_core.runnables.config import RunnableConfig

    messages = [HumanMessage(content="Add 3 and 4.")]
    messages = agent.invoke(
        {"messages": messages},
        config=RunnableConfig(run_name="Arithmetic Agent - Add 3+4")
    )
    for m in messages["messages"]:
        m.pretty_print()

## æ›¿æ¢ä¸ºåƒé—®å¤§æ¨¡å‹

ä¸Šé¢ä»£ç ï¼Œå¤§æ¨¡å‹éƒ¨åˆ†å·²ç»è¢«æ›¿æ¢æˆäº†åƒé—®çš„æ¨¡å‹ï¼Œä¸‹é¢æ˜¯æ›¿æ¢è¿‡ç¨‹

å®‰è£…å¿…è¦åŒ…ï¼š

    pip install langchain-core langchain-community dashscope

è·å– DashScope API Keyï¼š

*   è®¿é—® [é˜¿é‡Œäº‘ DashScope æ§åˆ¶å°](https://zhuanlan.zhihu.com/p/1983198808226694927/edit)
*   è·å– API Keyï¼ˆå¦‚ sk-xxxxxxï¼‰

è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰

ç”¨æˆ·ç›®å½•ä¸‹.envæ–‡ä»¶ï¼Œå¢åŠ 

    DASHSCOPE_API_KEY= ä½ çš„åƒé—®æ¨¡å‹api key

æ›¿æ¢æ¨¡å‹éƒ¨åˆ†ä»£ç 

    from dotenv import load_dotenv
    load_dotenv()# åŠ è½½ç¯å¢ƒå˜é‡
    from langchain_community.chat_models import ChatTongyi

    model = ChatTongyi(
        model="qwen-max",
        temperature=0,
        dashscope_api_key=os.getenv("DASHSCOPE_API_KEY")
    )

## æ‰§è¡Œæµç¨‹åˆ†æ

ä»æ‰“å°æ—¥å¿—å¯ä»¥çœ‹å‡ºï¼šè¯·æ±‚äº†ä¸¤æ¬¡å¤§æ¨¡å‹ï¼š

ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼š

*   å‘é€æ¶ˆæ¯ï¼š\[System, Human("Add 3 and 4.")]
*   è¿”å›æ¶ˆæ¯ï¼štool\_calls = \[{"name": "add", ...}]

ç¬¬äºŒæ¬¡è°ƒç”¨ï¼š

*   å‘é€æ¶ˆæ¯ï¼š\[System, Human("Add 3 and 4."), AI(tool\_calls), Tool("7")]
*   è¿”å›æ¶ˆæ¯ï¼šcontent = "The result is 7."

æˆ‘ä»¬æƒ³åŠæ³•çœ‹çœ‹æ•´ä¸ªæ‰§è¡Œè¿‡ç¨‹åˆ°åº•æ˜¯å¦‚ä½•è¿›è¡Œçš„

### æ–¹æ³•ä¸€ï¼šæ‰“å°æˆmermaidæ ¼å¼

è¢«æ³¨é‡Šæ‰çš„ä»£ç  # print(agent.get\_graph(xray=True).draw\_mermaid()) å¯ä»¥æ‰“å°mermaidæ ¼å¼çš„æµç¨‹å›¾ï¼Œåœ¨[https://mermaid.live](https://mermaid.live/)ä¸­å¯ä»¥ç”Ÿæˆæ‰§è¡Œæµç¨‹å›¾

    graph TD;
    	__start__([<p>__start__</p>]):::first
    	llm_call(llm_call)
    	tool_node(tool_node)
    	__end__([<p>__end__</p>]):::last
    	__start__ --> llm_call;
    	llm_call -.-> __end__;
    	llm_call -.-> tool_node;
    	tool_node --> llm_call;

![](https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/2e0ed1e19a2849c498bf7d2b177b1cbe~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5ram5rO95ou-5YWJ:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMTk2MzA1NzE5MjkyMjE3MCJ9&rk3s=f64ab15b&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1766301540&x-orig-sign=G2ht3a4iUwGrhEAdjMI1PddlX0w%3D)

æ·»åŠ å›¾ç‰‡æ³¨é‡Šï¼Œä¸è¶…è¿‡ 140 å­—ï¼ˆå¯é€‰ï¼‰

### æ–¹æ³•äºŒï¼šæ¥å…¥LangSmith

å¯ä»¥æ¥å…¥langchainå®˜ç½‘çš„LangSmithï¼Œæ¥å…¥éå¸¸ç®€å•ã€‚

âœ… ç¬¬ä¸€æ­¥ï¼šæ³¨å†Œå¹¶è·å– LangSmith å‡­æ®

1.  è®¿é—® <https://smith.langchain.com/>
2.  ç”¨ GitHub / Google è´¦å·ç™»å½•
3.  è¿›å…¥ Settings â†’ API Keys
4.  åˆ›å»ºä¸€ä¸ªæ–° API Keyï¼ˆæˆ–å¤åˆ¶å·²æœ‰ï¼‰
5.  åŒæ—¶è®°ä¸‹ä½ çš„ Project Nameï¼ˆé»˜è®¤æ˜¯ defaultï¼‰

âœ… ç¬¬äºŒæ­¥ï¼šå®‰è£… LangSmith SDK

    bashç¼–è¾‘


    pip install langsmith

> æ³¨æ„ï¼šlangchain >= 0.1.0 å·²å†…ç½®å¯¹ LangSmith çš„æ”¯æŒï¼Œæ— éœ€é¢å¤–å®‰è£… langchain-coreã€‚

âœ… ç¬¬ä¸‰æ­¥ï¼šè®¾ç½®ç¯å¢ƒå˜é‡

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶ï¼ˆå¦‚æœä½ è¿˜æ²¡åšï¼‰ï¼š

    envç¼–è¾‘

    # DashScope APIï¼ˆä½ å·²é…ç½®ï¼‰
    DASHSCOPE_API_KEY=sk-xxxxxx

    # ğŸ‘‡ æ–°å¢ LangSmith é…ç½®
    LANGCHAIN_TRACING_V2=true
    LANGCHAIN_API_KEY=lsk_xxxxxx  # ä» LangSmith æ§åˆ¶å°å¤åˆ¶
    LANGCHAIN_PROJECT=default      # æˆ–ä½ è‡ªå®šä¹‰çš„é¡¹ç›®å

> ğŸ”‘ å…³é”®å˜é‡è¯´æ˜ï¼š

*   LANGCHAIN\_TRACING\_V2=trueï¼šå¯ç”¨è¿½è¸ª
*   LANGCHAIN\_API\_KEYï¼šä½ çš„ LangSmith API Key
*   LANGCHAIN\_PROJECTï¼šæ•°æ®å½’é›†åˆ°å“ªä¸ªé¡¹ç›®ï¼ˆå¯é€‰ï¼Œé»˜è®¤ defaultï¼‰

ç„¶ååœ¨ä»£ç å¼€å¤´åŠ è½½ï¼š

    pythonç¼–è¾‘


    from dotenv import load_dotenv
    load_dotenv()  # ç¡®ä¿è¿™è¡Œåœ¨æœ€å‰é¢

âœ… ç¬¬å››æ­¥ï¼šä¸ºä½ çš„ Agent æ·»åŠ å”¯ä¸€ traceable åç§°ï¼ˆå¯é€‰ä½†æ¨èï¼‰

LangSmith ä¼šè‡ªåŠ¨è¿½è¸ªæ‰€æœ‰ LangChain è°ƒç”¨ï¼Œä½†ä½ å¯ä»¥ç»™ agent.invoke åŠ ä¸ªåå­—ä¾¿äºè¯†åˆ«ï¼š

    pythonç¼–è¾‘

    result = agent.invoke(
        {"messages": [HumanMessage(content="Add 3 and 4.")]},
        config={"run_name": "Arithmetic Agent"}
    )

âœ… ç¬¬äº”æ­¥ï¼šè¿è¡Œä½ çš„è„šæœ¬

åªè¦è®¾ç½®äº†ç¯å¢ƒå˜é‡ï¼Œæ‰€æœ‰ LangChain æ“ä½œï¼ˆLLM è°ƒç”¨ã€å·¥å…·è°ƒç”¨ã€èŠ‚ç‚¹æ‰§è¡Œï¼‰éƒ½ä¼šè‡ªåŠ¨ä¸ŠæŠ¥åˆ° LangSmithã€‚

âœ… ç¬¬å…­æ­¥ï¼šåœ¨ LangSmith æŸ¥çœ‹å¯è§†åŒ–æµç¨‹å›¾

1.  æ‰“å¼€ <https://smith.langchain.com/>
2.  è¿›å…¥ Datasets â†’ Tracesï¼ˆæˆ–ç›´æ¥ç‚¹å·¦ä¾§ "Traces"ï¼‰
3.  æ‰¾åˆ°ä½ åˆšè¿è¡Œçš„ traceï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰
4.  ç‚¹å‡»è¿›å…¥ï¼Œä½ ä¼šçœ‹åˆ°ï¼š

![](https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/6dffba83ccb246f6b02043acf014cfc0~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5ram5rO95ou-5YWJ:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMTk2MzA1NzE5MjkyMjE3MCJ9&rk3s=f64ab15b&x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&x-orig-expires=1766301540&x-orig-sign=WCN6LkUn3sw6UZ6VR5KYYO6DbVg%3D)

